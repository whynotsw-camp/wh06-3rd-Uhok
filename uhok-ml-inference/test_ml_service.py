#!/usr/bin/env python3
"""
ML ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ë¡œì»¬ì—ì„œ ML ì„œë¹„ìŠ¤ì˜ ë™ì‘ì„ í™•ì¸í•©ë‹ˆë‹¤.
"""

import asyncio
import httpx
import json
import time
from typing import Dict, Any

# í…ŒìŠ¤íŠ¸ ì„¤ì •
ML_SERVICE_URL = "http://localhost:8001"
TEST_TEXTS = [
    "ê°ˆë¹„íƒ•",
    "ê¹€ì¹˜ì°Œê°œ", 
    "ëœì¥ì°Œê°œ",
    "ë¶ˆê³ ê¸°",
    "ë¹„ë¹”ë°¥"
]

async def test_health_check() -> bool:
    """í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸...")
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(f"{ML_SERVICE_URL}/health")
            response.raise_for_status()
            
            data = response.json()
            print(f"âœ… í—¬ìŠ¤ì²´í¬ ì„±ê³µ: {data}")
            return True
    except Exception as e:
        print(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
        return False

async def test_single_embedding(text: str) -> Dict[str, Any]:
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
    print(f"ğŸ” ë‹¨ì¼ ì„ë² ë”© í…ŒìŠ¤íŠ¸: '{text}'")
    try:
        start_time = time.time()
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{ML_SERVICE_URL}/api/v1/embed",
                json={"text": text, "normalize": True}
            )
            response.raise_for_status()
            
            data = response.json()
            execution_time = time.time() - start_time
            
            print(f"âœ… ì„ë² ë”© ì„±ê³µ: ì°¨ì›={data['dim']}, ì‹œê°„={execution_time:.3f}ì´ˆ")
            return {
                "success": True,
                "dimension": data["dim"],
                "execution_time": execution_time,
                "embedding_preview": data["embedding"][:5]  # ì²˜ìŒ 5ê°œ ê°’ë§Œ
            }
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        return {"success": False, "error": str(e)}

async def test_batch_embedding(texts: list) -> Dict[str, Any]:
    """ë°°ì¹˜ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
    print(f"ğŸ” ë°°ì¹˜ ì„ë² ë”© í…ŒìŠ¤íŠ¸: {len(texts)}ê°œ í…ìŠ¤íŠ¸")
    try:
        start_time = time.time()
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"{ML_SERVICE_URL}/api/v1/embed-batch",
                json={"texts": texts, "normalize": True}
            )
            response.raise_for_status()
            
            data = response.json()
            execution_time = time.time() - start_time
            
            print(f"âœ… ë°°ì¹˜ ì„ë² ë”© ì„±ê³µ: ì²˜ë¦¬ìˆ˜={data['count']}, ì‹œê°„={execution_time:.3f}ì´ˆ")
            return {
                "success": True,
                "count": data["count"],
                "dimension": data["dim"],
                "execution_time": execution_time
            }
    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        return {"success": False, "error": str(e)}

async def test_model_info() -> Dict[str, Any]:
    """ëª¨ë¸ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ëª¨ë¸ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸...")
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(f"{ML_SERVICE_URL}/api/v1/model-info")
            response.raise_for_status()
            
            data = response.json()
            print(f"âœ… ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì„±ê³µ: {data}")
            return {"success": True, "info": data}
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"success": False, "error": str(e)}

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ ML ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“ ì„œë¹„ìŠ¤ URL: {ML_SERVICE_URL}")
    print("=" * 50)
    
    # 1. í—¬ìŠ¤ì²´í¬
    health_ok = await test_health_check()
    if not health_ok:
        print("âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
        return
    
    print()
    
    # 2. ëª¨ë¸ ì •ë³´ ì¡°íšŒ
    await test_model_info()
    print()
    
    # 3. ë‹¨ì¼ ì„ë² ë”© í…ŒìŠ¤íŠ¸
    single_results = []
    for text in TEST_TEXTS[:3]:  # ì²˜ìŒ 3ê°œë§Œ í…ŒìŠ¤íŠ¸
        result = await test_single_embedding(text)
        single_results.append(result)
        print()
    
    # 4. ë°°ì¹˜ ì„ë² ë”© í…ŒìŠ¤íŠ¸
    batch_result = await test_batch_embedding(TEST_TEXTS)
    print()
    
    # 5. ê²°ê³¼ ìš”ì•½
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 50)
    
    successful_single = sum(1 for r in single_results if r.get("success", False))
    print(f"ë‹¨ì¼ ì„ë² ë”©: {successful_single}/{len(single_results)} ì„±ê³µ")
    
    if batch_result.get("success", False):
        print(f"ë°°ì¹˜ ì„ë² ë”©: ì„±ê³µ ({batch_result['count']}ê°œ ì²˜ë¦¬)")
    else:
        print(f"ë°°ì¹˜ ì„ë² ë”©: ì‹¤íŒ¨")
    
    # ì„±ëŠ¥ í†µê³„
    single_times = [r.get("execution_time", 0) for r in single_results if r.get("success", False)]
    if single_times:
        avg_time = sum(single_times) / len(single_times)
        print(f"í‰ê·  ì„ë² ë”© ì‹œê°„: {avg_time:.3f}ì´ˆ")
    
    if batch_result.get("success", False):
        batch_time = batch_result.get("execution_time", 0)
        batch_count = batch_result.get("count", 1)
        print(f"ë°°ì¹˜ í‰ê·  ì‹œê°„: {batch_time/batch_count:.3f}ì´ˆ/ê°œ")
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(main())
